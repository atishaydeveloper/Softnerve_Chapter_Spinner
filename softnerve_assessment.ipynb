{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c1de237-e930-4cba-ade9-cd73736719f6",
   "metadata": {},
   "source": [
    "## Softnerve - Chapter Spinner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f9d48f-c467-4eea-a153-aabbc4a63711",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84e076f5-0951-476f-9682-a1077259ebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import gradio as gr\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "import requests\n",
    "from IPython.display import Image\n",
    "import gradio as gr\n",
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq, pipeline\n",
    "from huggingface_hub import login\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6533eb9b-7b77-417f-922d-c0c9184f9022",
   "metadata": {},
   "source": [
    "#### Initializing Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0804f05c-1316-41e8-afb8-f59dc4f0d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  \n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "\n",
    "MODEL = \"gemini-2.5-flash\"\n",
    "db_name = \"vector_db\"\n",
    "\n",
    "load_dotenv()\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "gemini = OpenAI(\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    "    api_key= google_api_key\n",
    ")\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "hf_token = os.getenv('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bbd67f-89a7-46ad-854c-0918f6491072",
   "metadata": {},
   "source": [
    "#### Setting up the Audio Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ec344c84-0109-44e6-8fb8-82ce770aae02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "AUDIO_MODEL = \"openai/whisper-medium\"\n",
    "processor = AutoProcessor.from_pretrained(AUDIO_MODEL)\n",
    "speech_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    AUDIO_MODEL,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_safetensors=True\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=speech_model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch.float16,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802b0b8e-e34d-4fc0-b1f7-7fd07a36874f",
   "metadata": {},
   "source": [
    "#### Scrapping the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5cc51435-334f-48bc-92a8-1fa5d0308d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    def __init__(self,url):\n",
    "        self.url = url\n",
    "        driver.get(url)\n",
    "        source = driver.page_source\n",
    "        soup = BeautifulSoup(source, 'html.parser')\n",
    "        self.title = driver.title if driver.title else \"unknown\"\n",
    "        self.image_path = f\"{url[-9:]}.png\"\n",
    "        driver.save_screenshot(self.image_path)\n",
    "        self.screenshot = self.image_path\n",
    "        for irrelevant in soup.body(['style','script', 'img', 'input']):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\",strip=True)[1100:-500]\n",
    "        links = [link.get('href') for link in soup.find_all('a',)]\n",
    "        self.links = [link for link in links if link]\n",
    "        \n",
    "    def get_contents(self):\n",
    "        return f\"Title: {self.title}\\n\\nText: {self.text}\"\n",
    "\n",
    "    def view_screenshot(self):\n",
    "        if isinstance(self.screenshot, str):\n",
    "            display(Image(filename=self.screenshot))\n",
    "        else:\n",
    "            print(\"Screenshot path is not valid.\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9174e3b0-a975-47ab-a5b1-9734e9fa5566",
   "metadata": {},
   "source": [
    "#### Style Selection and Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05d3a418-0234-431f-8d77-892a28b270f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spin_styles = {\n",
    "    \"Simplified\": \"simplified version\",\n",
    "    \"Dramatic\": \"more dramatic version\",\n",
    "    \"Poetic\": \"poetic and lyrical version\",\n",
    "    \"Modern\": \"modern and casual version\",\n",
    "    \"First-Person\": \"first-person perspective rewrite\",\n",
    "    \"Child-Friendly\": \"version suitable for children aged 10-12\",\n",
    "    \"Academic\": \"formal and academic version\",\n",
    "}\n",
    "\n",
    "def spin_style_chose(user_choice):\n",
    "    if user_choice in spin_styles.keys():\n",
    "        style = spin_styles[\"Simplified\"]\n",
    "    return f\"{user_choice}:{style}\"\n",
    "\n",
    "def chapter_to_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2a3216-c195-4cfd-84f7-d99b45948e4d",
   "metadata": {},
   "source": [
    "#### System and User Prompt generation for Writer and Reviewer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "25c008c5-c412-4dc7-9999-877433336807",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_system_prompt = \"\"\"\n",
    "    You are an AI Writing Agent named 'ChapterSpinner'. \n",
    "    Your job is to rewrite book chapters in different styles while preserving the original meaning, character emotions, and storyline.\n",
    "    Be creative but do not add or remove plot points.\n",
    "\"\"\"\n",
    "\n",
    "def writer_user_prompt(user_choice, chapter_content):\n",
    "    writer_user_prompt_template = f\"\"\"\n",
    "        Rewrite the following chapter into a {spin_style_chose(user_choice)}. \n",
    "        Keep the core meaning, storyline, and details intact, but change the tone, sentence structure, and language to match the target style. \n",
    "        Do not invent events or characters.\n",
    "        === ORIGINAL CHAPTER ==={chapter_content}\n",
    "    \"\"\"\n",
    "    return writer_user_prompt_template\n",
    "\n",
    "reviewer_system_prompt = \"\"\"\n",
    "    You are an AI Reviewer Agent named 'ChapterPolisher'.\n",
    "    Your role is to refine AI-generated rewritten chapters for grammar, coherence, and tone consistency without altering the intended style or meaning.\n",
    "\"\"\"\n",
    "\n",
    "def reviewer_user_prompt(user_choice, rewritten_chapter):\n",
    "    reviewer_user_prompt_template = f\"\"\"\n",
    "    Refine the following rewritten chapter to improve grammar, sentence flow, and tone consistency while maintaining its {spin_style_chose(user_choice)}.\n",
    "    Make the transitions smoother and ensure clarity and readability. Do not change the storyline or remove meaningful content.\n",
    "    === REWRITTEN CHAPTER ===\\n{rewritten_chapter}\n",
    "    \"\"\"\n",
    "    return reviewer_user_prompt_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c26642-eb46-4aba-a347-baa1a416aeaa",
   "metadata": {},
   "source": [
    "#### Creating a versions.json file to store Versions and Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0d021248-257a-4e54-a28d-12f93b7b319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def versioning(stars, reviewed_chapter, updated_chapter, chapter_no):\n",
    "    import json, os\n",
    "    version_name = f\"version_{int(time.time())}\"  # use timestamp to ensure uniqueness\n",
    "    reward = -1 if int(stars) <= 2 else (0 if int(stars) == 3 else 1)\n",
    "\n",
    "    if updated_chapter:\n",
    "        version_entry = {\n",
    "        \"Version\": version_name,\n",
    "        \"Content\": updated_chapter,\n",
    "        \"Reward\": reward\n",
    "    }\n",
    "    else:\n",
    "    \n",
    "        version_entry = {\n",
    "            \"Version\": version_name,\n",
    "            \"Content\": reviewed_chapter,\n",
    "            \"Reward\": reward\n",
    "        }\n",
    "\n",
    "    filename = \"versions.json\"\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            all_versions = json.load(f)\n",
    "    else:\n",
    "        all_versions = {}\n",
    "\n",
    "    chapter_key = f\"Chapter{chapter_no}\"\n",
    "\n",
    "    if chapter_key not in all_versions:\n",
    "        all_versions[chapter_key] = []\n",
    "\n",
    "    all_versions[chapter_key].append(version_entry)\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(all_versions, f, indent=4)\n",
    "\n",
    "    print(f\"Version for {chapter_key} saved successfully.\")\n",
    "    return f\"Saved {version_name} for {chapter_key} with reward: {reward}\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92934bd6-b6c0-4732-9c13-7944a63f78d1",
   "metadata": {},
   "source": [
    "#### Setting up the connection between Both the Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7e69f78a-8ed9-4998-8952-9f6a83d0a69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter = None  \n",
    "conversation_chain = None  \n",
    "reviewed_chapter = \"\"\n",
    "final_chapter = \"\"\n",
    "\n",
    "\n",
    "def handle_initial_inputs(book_no, chapter_no, style_choice):\n",
    "    global chapter, reviewed_chapter\n",
    "    if int(book_no) < 4:\n",
    "        if int(book_no) ==1:\n",
    "            if int(chapter_no) >= 14:\n",
    "                return \"Invalid chapter number. Must be less than 14.\", \"\", \"\"\n",
    "        elif int(book_no) ==2:\n",
    "            if int(chapter_no) >= 10:\n",
    "                return \"Invalid chapter number. Must be less than 10.\", \"\", \"\"\n",
    "        elif int(book_no) ==3:\n",
    "            if int(chapter_no) >= 9:\n",
    "                return \"Invalid chapter number. Must be less than 9.\", \"\", \"\"\n",
    "        elif int(book_no) ==4:\n",
    "            if int(chapter_no) >= 13:\n",
    "                return \"Invalid chapter number. Must be less than 13.\", \"\", \"\"\n",
    "        else:\n",
    "            return \"Invalid book number. Must be less than 5.\", \"\", \"\"\n",
    "            \n",
    "    url = f\"https://en.wikisource.org/wiki/The_Gates_of_Morning/Book_{book_no}/Chapter_{chapter_no}\"\n",
    "    chapter = Website(url)\n",
    "\n",
    "    content = chapter.get_contents()\n",
    "\n",
    "    # Writer + Reviewer flow\n",
    "    writer_message = [\n",
    "        {\"role\": \"system\", \"content\": writer_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": writer_user_prompt(style_choice, content)}\n",
    "    ]\n",
    "    writer_response = gemini.chat.completions.create(model=MODEL, messages=writer_message)\n",
    "    rewritten_chapter = writer_response.choices[0].message.content\n",
    "\n",
    "    reviewer_message = [\n",
    "        {\"role\": \"system\", \"content\": reviewer_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": reviewer_user_prompt(style_choice, rewritten_chapter)}\n",
    "    ]\n",
    "    reviewer_response = gemini.chat.completions.create(model=MODEL, messages=reviewer_message)\n",
    "    reviewed_chapter = reviewer_response.choices[0].message.content\n",
    "\n",
    "    update_vectorstore(reviewed_chapter)\n",
    "    return \"Chapter Reviewed\", reviewed_chapter, reviewed_chapter "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf472fa-fa1b-443b-b194-f409e9b00d15",
   "metadata": {},
   "source": [
    "#### Applying Human in the Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b90ac408-2648-45d9-9db5-e644e774532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_instruction(instruction_text, current_text):\n",
    "    prompt = f\"Apply the following instruction to the reviewed chapter: '{instruction_text}'\\n\\nChapter:\\n{current_text}\"\n",
    "    response = gemini.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    new_text = response.choices[0].message.content\n",
    "    update_vectorstore(new_text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2695f1-ed6e-456e-b7d9-5d03fe451326",
   "metadata": {},
   "source": [
    "#### Generating Embeddings and Defining vectordatabase for each Chapter generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b43bb21-f4b7-47f6-85d5-2654a2539c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vectorstore(final_text):\n",
    "    global conversation_chain\n",
    "    chunks = chapter_to_chunks(final_text)\n",
    "\n",
    "    if os.path.exists(db_name):\n",
    "        Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "    vectorstore = Chroma.from_texts(chunks, embedding=embeddings)\n",
    "    llm = ChatGoogleGenerativeAI(temperature=0.7, model=MODEL)\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 25})\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)\n",
    "    print(\"RAG pipeline initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9038a3-0d00-495b-bf2b-0b086967bcb3",
   "metadata": {},
   "source": [
    "#### Setting up Screenshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0aa0e219-623b-46ab-b803-c1151ce4ea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(book_no, chapter_no):\n",
    "    try:\n",
    "        chapter_no = int(chapter_no)\n",
    "        if int(book_no) < 4:\n",
    "            if int(book_no) ==1:\n",
    "                if int(chapter_no) >= 14:\n",
    "                    return \"Invalid chapter number. Must be less than 14.\", \"\", \"\"\n",
    "            elif int(book_no) ==2:\n",
    "                if int(chapter_no) >= 10:\n",
    "                    return \"Invalid chapter number. Must be less than 10.\", \"\", \"\"\n",
    "            elif int(book_no) ==3:\n",
    "                if int(chapter_no) >= 9:\n",
    "                    return \"Invalid chapter number. Must be less than 9.\", \"\", \"\"\n",
    "            elif int(book_no) ==4:\n",
    "                if int(chapter_no) >= 13:\n",
    "                    return \"Invalid chapter number. Must be less than 13.\", \"\", \"\"\n",
    "            else:\n",
    "                return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    url = f\"https://en.wikisource.org/wiki/The_Gates_of_Morning/Book_{book_no}/Chapter_{chapter_no}\"\n",
    "    chapter = Website(url)\n",
    "\n",
    "    return chapter.screenshot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e075294c-7ff2-4cad-a90e-97cf433853e4",
   "metadata": {},
   "source": [
    "#### Setting up a Pipeline to handle chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d72a98d2-8853-4021-b37b-a2490381aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_chat(message, history):\n",
    "    if history is None:\n",
    "        history = []\n",
    "        \n",
    "    if conversation_chain is None:\n",
    "        return history + [[message, \"Please enter chapter number first.\"]]\n",
    "        \n",
    "    print(\"conversation_chain exists:\", conversation_chain is not None)\n",
    "\n",
    "    try:\n",
    "        result = conversation_chain.invoke({\"question\": message})\n",
    "        bot_response = result[\"answer\"]\n",
    "        history.append([message, bot_response]) \n",
    "    except Exception as e:\n",
    "        history.append([message, f\"Error: {str(e)}\"])\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28729d0a-a00b-4296-bba4-192bb745efd8",
   "metadata": {},
   "source": [
    "#### Function to transcribe Audio to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cbfe9c1c-a0ed-4865-bda7-bccc29c875cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(audiofile):\n",
    "    try:\n",
    "        if audiofile is None:\n",
    "            return \"No audio file received.\"\n",
    "\n",
    "        print(\"[INFO] Transcribing:\", audiofile)\n",
    "        result = pipe(audiofile, return_timestamps=True)\n",
    "        transcription = result[\"text\"]\n",
    "        print(\"[INFO] Transcription complete:\", transcription[:100])\n",
    "        return transcription\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"[ERROR] Failed to transcribe audio:\", str(e))\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3382e6b7-a1a8-4274-94f6-4c63439eb4bd",
   "metadata": {},
   "source": [
    "#### Setting up a Pipeline to handle voice based chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8040d63d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def voice_to_chat(audio_path, chat_history=None):\n",
    "    if chat_history is None:\n",
    "        chat_history = []\n",
    "\n",
    "    transcription = process_audio(audio_path)\n",
    "\n",
    "    if conversation_chain is None:\n",
    "        chat_history.append([transcription, \"Please enter chapter number first.\"])\n",
    "    else:\n",
    "        try:\n",
    "            result = conversation_chain.invoke({\"question\": transcription})\n",
    "            bot_response = result[\"answer\"]\n",
    "            chat_history.append([transcription, bot_response])\n",
    "        except Exception as e:\n",
    "            chat_history.append([transcription, f\"Error: {str(e)}\"])\n",
    "\n",
    "    return chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896fbd22-f047-4f32-a866-67fa8edeb5dd",
   "metadata": {},
   "source": [
    "#### Gradio Interface for better interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bede7113-37ce-4862-a7c7-967b51867121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_36764\\860229548.py:26: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot()\n",
      "D:\\anaconda\\envs\\gpu_env\\lib\\site-packages\\gradio\\utils.py:1074: UserWarning: Expected 2 arguments for function <function handle_chat at 0x0000020EAF6CBEB0>, received 1.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\gpu_env\\lib\\site-packages\\gradio\\utils.py:1078: UserWarning: Expected at least 2 arguments for function <function handle_chat at 0x0000020EAF6CBEB0>, received 1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG pipeline initialized successfully.\n",
      "RAG pipeline initialized successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\gpu_env\\lib\\site-packages\\gradio\\helpers.py:1031: UserWarning: Unexpected argument. Filling with None.\n",
      "  warnings.warn(\"Unexpected argument. Filling with None.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversation_chain exists: True\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## AI-Powered Chapter Spinner\")\n",
    "\n",
    "    with gr.Row():\n",
    "        book_no = gr.Textbox(label=\"Enter Book Number (1-4)\", value=None)\n",
    "        chapter_no = gr.Textbox(label=\"Enter Chapter Number\", value=None)\n",
    "        style_choice = gr.Dropdown(choices=list(spin_styles.keys()), label=\"Choose Rewrite Style\", value=\"Simplified\")\n",
    "        submit_button = gr.Button(\"Generate Chapter\")\n",
    "\n",
    "    with gr.Row():\n",
    "        \n",
    "        image_output = gr.Image(label=\"Scrapped Image\")\n",
    "\n",
    "    \n",
    "    status = gr.Textbox(label=\"Status Message\", interactive=False)\n",
    "    reviewed_output = gr.Textbox(label=\"Reviewed Chapter Output\", lines=20)\n",
    "\n",
    "    with gr.Row():\n",
    "        manual_edit_box = gr.Textbox(label=\"Edit Chapter Manually\", lines=15)\n",
    "        instruction_box = gr.Textbox(label=\"Or Give Instructions to Improve\")\n",
    "\n",
    "    apply_instruction_btn = gr.Button(\"Apply Instruction\")\n",
    "\n",
    "    updated_output = gr.Textbox(label=\"Final Chapter After Instruction or Manual Edits\", lines=20)\n",
    "\n",
    "    chatbot = gr.Chatbot()\n",
    "    user_query = gr.Textbox(label=\"Ask Questions About the Chapter\")\n",
    "    with gr.Row():\n",
    "        audio_input = gr.Audio(type=\"filepath\", label=\"Upload or Record Audio\")\n",
    "        \n",
    "        \n",
    "        transcribe_button = gr.Button(\"Transcribe\")\n",
    "        ask_btn = gr.Button(\"Ask\")\n",
    "        \n",
    "    rating = gr.Radio(choices=[\"1\", \"2\", \"3\", \"4\", \"5\"], label=\"Rate the AI's Output\", interactive=True)\n",
    "    rate_button = gr.Button(\"Submit Rating\")\n",
    "    status = gr.Textbox(label=\"Status Message\", interactive=False)\n",
    "\n",
    "    submit_button.click(handle_initial_inputs, inputs=[book_no, chapter_no, style_choice], outputs=[status, reviewed_output, manual_edit_box])\n",
    "    chapter_no.change(fn=get_image, inputs=[book_no, chapter_no], outputs=image_output)\n",
    "    apply_instruction_btn.click(apply_instruction, inputs=[instruction_box, manual_edit_box], outputs=updated_output)\n",
    "    transcribe_button.click(fn= voice_to_chat, inputs=audio_input, outputs=chatbot)\n",
    "    ask_btn.click(handle_chat, inputs=user_query, outputs=chatbot)\n",
    "    rate_button.click(\n",
    "    fn=versioning,\n",
    "    inputs=[rating, reviewed_output, updated_output, chapter_no],\n",
    "    outputs=status\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "demo.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b016049f-24e9-4f1b-b51d-3b8890ab374c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
